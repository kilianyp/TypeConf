{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typeconf import SelectConfig, BaseConfig\n",
    "from pydantic import ValidationError\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access predefined Configurations for a torch optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typeconf.libs.torch.optim import OptimizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register some Non-Linearities we later want to quickly switch out.\n",
    "The name passed in register is later used in the configuration to specify which one we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearityConfig(SelectConfig):\n",
    "    pass\n",
    "\n",
    "# Same class must be used in register as well as in inheritance\n",
    "@NonLinearityConfig.register('sigmoid')\n",
    "class Sigmoid(NonLinearityConfig):\n",
    "    def build(self):\n",
    "        return torch.sigmoid\n",
    "\n",
    "@NonLinearityConfig.register('tanh')\n",
    "class Tanh(NonLinearityConfig):\n",
    "    def build(self):\n",
    "        return torch.tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register some models. Here we use the NonLinearityConfig. In the build function, we dynamically get the correct non-linearity and pass it to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(SelectConfig):\n",
    "    pass\n",
    "\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, activation_fn, kernel_size):\n",
    "        super().__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "        self.conv1 = nn.Conv2d(3, 3, kernel_size=kernel_size)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.activation_fn(x)\n",
    "\n",
    "# Using the configuration from\n",
    "@ModelConfig.register('ConvNetwork')\n",
    "class ConvModelConfig(ModelConfig):\n",
    "    activation_fn : NonLinearityConfig\n",
    "    kernel_size : Union[Tuple[int, int], int] = (3, 3)\n",
    "    def build(self):\n",
    "        activation_fn = self.activation_fn.build()\n",
    "        return ConvModel(activation_fn, self.kernel_size)\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, activation_fn, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "        self.fc1 = nn.Linear(in_features, out_features)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return self.activation_fn(x)\n",
    "\n",
    "@ModelConfig.register('LinearNetwork')\n",
    "class LinearModelConfig(ModelConfig):\n",
    "    activation_fn : NonLinearityConfig\n",
    "    in_features : int = 10\n",
    "    out_features : int = 10\n",
    "    def build(self):\n",
    "        activation_fn = self.activation_fn.build()\n",
    "        return LinearModel(activation_fn, self.in_features, self.out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a overall experiment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentConfig(BaseConfig):\n",
    "    model : ModelConfig\n",
    "    optimizer : OptimizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few configurations to test out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cfg):\n",
    "    cfg = ExperimentConfig(**cfg)\n",
    "    print(cfg)\n",
    "\n",
    "    model = cfg.model.build()\n",
    "    print(model) \n",
    "    print(model.activation_fn)\n",
    "    optimizer = cfg.optimizer.build(model.parameters())\n",
    "    print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=LinearModelConfig(name='LinearNetwork', activation_fn=Sigmoid(name='sigmoid'), in_features=10, out_features=10) optimizer=AdagradConfig(name='Adagrad', lr=0.01, lr_decay=0, eps=1e-10, initial_accumulator_value=0.0, weight_decay=0)\n",
      "LinearModel(\n",
      "  (fc1): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "<built-in method sigmoid of type object at 0x10ebd1c30>\n",
      "Adagrad (\n",
      "Parameter Group 0\n",
      "    eps: 1e-10\n",
      "    initial_accumulator_value: 0.0\n",
      "    lr: 0.01\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cfg1 = {\n",
    "    'model': {\n",
    "        'name': 'LinearNetwork',\n",
    "        'activation_fn': {\n",
    "            'name': 'sigmoid'\n",
    "        }\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'Adagrad'\n",
    "    }\n",
    "}\n",
    "\n",
    "run(cfg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=ConvModelConfig(name='ConvNetwork', activation_fn=Tanh(name='tanh'), kernel_size=(3, 3)) optimizer=AdagradConfig(name='Adagrad', lr=0.01, lr_decay=0, eps=1e-10, initial_accumulator_value=0.0, weight_decay=0)\n",
      "ConvModel(\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "<built-in method tanh of type object at 0x10ebd1c30>\n",
      "Adagrad (\n",
      "Parameter Group 0\n",
      "    eps: 1e-10\n",
      "    initial_accumulator_value: 0.0\n",
      "    lr: 0.01\n",
      "    lr_decay: 0\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cfg2 = {\n",
    "    'model': {\n",
    "        'name': 'ConvNetwork',\n",
    "        'activation_fn': {\n",
    "            'name': 'tanh'\n",
    "        }\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'Adagrad'\n",
    "    }\n",
    "}\n",
    "run(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avoid runtime error because option does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n",
      "1 validation error for ExperimentConfig\n",
      "model -> activation_fn\n",
      "  Unknown option for NonLinearityConfig: relu (type=value_error)\n"
     ]
    }
   ],
   "source": [
    "cfg_wrong_model_name = {\n",
    "    'model': {\n",
    "        'name': 'ConvNetwork',\n",
    "        'activation_fn': {\n",
    "            'name': 'relu'\n",
    "        }\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'Adadelta'\n",
    "    }\n",
    "}\n",
    "try:\n",
    "    run(cfg_wrong_model_name)\n",
    "except ValueError as e:\n",
    "    print('Error!')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n",
      "2 validation errors for ExperimentConfig\n",
      "model -> kernel_size\n",
      "  wrong tuple length 3, expected 2 (type=value_error.tuple.length; actual_length=3; expected_length=2)\n",
      "model -> kernel_size\n",
      "  value is not a valid integer (type=type_error.integer)\n"
     ]
    }
   ],
   "source": [
    "# avoid runtime error because of invalid data type\n",
    "cfg_wrong_kernel_size = {\n",
    "    'model': {\n",
    "        'name': 'ConvNetwork',\n",
    "        'kernel_size': (3, 3, 3),\n",
    "        'activation_fn': {\n",
    "            'name': 'tanh'\n",
    "        }\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'Adagrad'\n",
    "    }\n",
    "}\n",
    "try:\n",
    "    run(cfg_wrong_kernel_size)\n",
    "except ValueError as e:\n",
    "    print('Error!')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoid default value being used because wrong naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n",
      "1 validation error for ExperimentConfig\n",
      "model -> kernel_sizze\n",
      "  extra fields not permitted (type=value_error.extra)\n"
     ]
    }
   ],
   "source": [
    "cfg_wrong_kernel_size_name = {\n",
    "    'model': {\n",
    "        'name': 'ConvNetwork',\n",
    "        'kernel_sizze': (3, 3),\n",
    "        'activation_fn': {\n",
    "            'name': 'tanh'\n",
    "        }\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'name': 'Adagrad'\n",
    "    }\n",
    "}\n",
    "try:\n",
    "    run(cfg_wrong_kernel_size_name)\n",
    "except ValidationError as e:\n",
    "    print('Error!')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration can also be modified directly from CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ExperimentConfig._create_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ExperimentConfig [-h] [--config_path CONFIG_PATH]\n",
      "                        [--model.name {convnetwork,linearnetwork}]\n",
      "                        [--optimizer.name {adadelta,adagrad}]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --config_path CONFIG_PATH\n",
      "  --model.name {convnetwork,linearnetwork}\n",
      "  --optimizer.name {adadelta,adagrad}\n"
     ]
    }
   ],
   "source": [
    "parser.print_help()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
